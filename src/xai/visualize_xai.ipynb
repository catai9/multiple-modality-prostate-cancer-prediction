{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3, 12, 84, 84)\n",
            "torch.Size([1, 3, 12, 84, 84])\n",
            "torch.Size([1, 1, 12, 84, 84])\n",
            "(1, 1, 12, 84, 84)\n",
            "(3, 12, 84, 84)\n",
            "torch.Size([1, 3, 12, 84, 84])\n",
            "torch.Size([1, 1, 12, 84, 84])\n",
            "(1, 1, 12, 84, 84)\n",
            "(3, 12, 84, 84)\n",
            "torch.Size([1, 3, 12, 84, 84])\n",
            "torch.Size([1, 1, 12, 84, 84])\n",
            "(1, 1, 12, 84, 84)\n",
            "(3, 12, 84, 84)\n",
            "torch.Size([1, 3, 12, 84, 84])\n",
            "torch.Size([1, 1, 12, 84, 84])\n",
            "(1, 1, 12, 84, 84)\n"
          ]
        }
      ],
      "source": [
        "# Import M3d-CAM\n",
        "from medcam import medcam\n",
        "import torch\n",
        "from get_model import get_trained_model\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "%matplotlib inline\n",
        "\n",
        "BACKENDS = [\"gcampp\", \"gcam\", \"gbp\", \"ggcam\"]\n",
        "MODALITIES = [\"DWI\", \"T2W\", \"ADC\"]\n",
        "\n",
        "pairings = [\n",
        "    [139,197],\n",
        "    [17, 175],\n",
        "    [93, 55],\n",
        "    [95, 67],\n",
        "    [118, 85]\n",
        "]\n",
        "\n",
        "def setup_image(image: np.array, slice: int, modality: int):\n",
        "    data = np.transpose(image, (2, 3, 0, 1))\n",
        "    data = data[modality, :, :, slice]\n",
        "    normalized_image = (data-np.min(data))/(np.max(data)-np.min(data)) * 255\n",
        "    normalized_image = normalized_image.astype(np.uint8)\n",
        "    normalized_image = cv2.resize(normalized_image, (84, 84))\n",
        "    return normalized_image\n",
        "\n",
        "for i in pairings:\n",
        "    patient_id = i[1]\n",
        "    fold = i[0]\n",
        "    MODEL_PATH = f'pca-results/3_modalities_cropped_T2W_clinical_sig/best_weights/best_metric_model_fold_{fold}.pth'\n",
        "    SAVE_DIR = f\"pca-results/attention_maps/3_modalities_v2/{patient_id}/individual_modalities\"\n",
        "    IMAGE_PATH = f'data/pca_processed_data/3_modalities_combined/ProstateX-{str(patient_id).zfill(4)}_multi_modal_img.npy'\n",
        "    for backend in BACKENDS:\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        model = get_trained_model(MODEL_PATH)\n",
        "        model = model.to(device)\n",
        "        # replace so that doesn't save the attention map to the directory \n",
        "        model = medcam.inject(model, output_dir=\"attention_maps\", save_maps=True, backend=backend, layer=\"auto\", replace=True)\n",
        "        model.eval()\n",
        "\n",
        "        image_data = np.load(IMAGE_PATH)\n",
        "        print(image_data.shape) # (3, 12, 84, 84)\n",
        "\n",
        "        new_input = torch.from_numpy(np.array([image_data])).float().to(device)\n",
        "        print(new_input.shape) # torch.Size([1, 3, 12, 84, 84])\n",
        "\n",
        "        output = model(new_input)\n",
        "        print(output.shape) # torch.Size([1, 1, 12, 84, 84])\n",
        "\n",
        "        output_np = output.cpu().numpy()\n",
        "\n",
        "        output_np = (output_np - np.min(output_np)) / (np.max(output_np) - np.min(output_np)) # normalizing\n",
        "        print(output_np.shape)\n",
        "        num_slices = output_np.shape[2]  # Get the number of slices\n",
        "\n",
        "        # Set up the figure size and layout\n",
        "        for modality in range(3):\n",
        "            fig, axes = plt.subplots(3, 4, figsize=(15, 10))\n",
        "            axes = axes.flatten()\n",
        "\n",
        "            for slice in range(num_slices):\n",
        "                ax = axes[slice]\n",
        "                ax.imshow(setup_image(image_data, slice, modality))  # Overlay with mask\n",
        "                ax.imshow(output_np[0, 0, slice, :, :], cmap='jet', alpha=0.5)\n",
        "                ax.axis('off') \n",
        "                ax.set_title(f'Slice {slice+1}')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "            plt.savefig(f\"{SAVE_DIR}/{backend}-{MODALITIES[modality]}.png\")\n",
        "            plt.close(fig)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pca-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
